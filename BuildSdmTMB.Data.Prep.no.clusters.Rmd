---
title: "BuildSdmTMB Data Prep No Clusters"
author: "Stephanie Hopkins"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: TRUE
    
---

```{r setup, include=FALSE}

# Run first if not already installed
# remotes::install_github("pbs-assess/sdmTMBextra", dependencies = TRUE)
# remotes::install_github("pbs-assess/sdmTMB", dependencies = TRUE)

rm(list=ls())
gc()

load.lib <- c("tidyverse", "data.table", "cowplot", "sf", "rcompanion",
              "pROC", "here", "sdmTMB", "sdmTMBextra", "visreg",
              "utils", "ggforce", # enables plot_anisotropy
              "spatstat",# Get summary table for nearest neighbor
              "rsample", "timetk", "zoo") 

install.lib <- load.lib[!load.lib %in% installed.packages()]

for(lib in install.lib) install.packages(lib,dependencies=TRUE)
sapply(load.lib,require,character=TRUE)

sf_use_s2(FALSE)

dir <- here(getwd())

```

# Load new sdm data

```{r, load.new.dat}

no.cluster.2003.2005 <- 
   read_sf(here(dir, "Data", "Shapefiles", "no.clust.sf.2003.2005.shp"))
# View(no.cluster.2003.2005)

colnames(no.cluster.2003.2005)
plotNormalDensity(no.cluster.2003.2005$Dnsty_n_3)

no.cluster.2006.2010 <- 
   read_sf(here(dir, "Data", "Shapefiles", "no.clust.sf.2006.2010.shp"))
# View(no.cluster.2006.2010)
plotNormalDensity(no.cluster.2006.2010$Dnsty_n_3)

no.cluster.2011.2014 <- 
   read_sf(here(dir, "Data", "Shapefiles", "no.clust.sf.2011.2014.shp"))
# View(no.cluster.2011.2014)
plotNormalDensity(no.cluster.2011.2014$Dnsty_n_3)

no.cluster.2015.2020 <- 
   read_sf(here(dir, "Data", "Shapefiles", "no.clust.sf.2015.2020.shp"))
# View(no.cluster.2015.2020)
plotNormalDensity(no.cluster.2015.2020$Dnsty_n_3)

no.cluster.2021.2024 <- 
   read_sf(here(dir, "Data", "Shapefiles", "no.clust.sf.2021.2024.shp"))
# View(no.cluster.2021.2024)
plotNormalDensity(no.cluster.2021.2024$Dnsty_n_3)

full.dat <- rbind(no.cluster.2003.2005, no.cluster.2006.2010, no.cluster.2011.2014,
                  no.cluster.2015.2020, no.cluster.2021.2024)
head(full.dat$dattmPC) 
plotNormalDensity(full.dat$Dnsty_n_3)

```

## Load Coastal Geometry

```{r, load.land.shp}

land.barrier <- read_sf(here(dir, "Data", "Shapefiles", "land.barrier.shp"))

# Read full resolution - Continental land masses and ocean islands, except Antarctica.
##land.barrier <- read_sf(here(dir, "Data", "Shapefiles", "gshhg-shp-2.3.7",
##                             "GSHHS_shp", "f", "GSHHS_f_L1.shp")) %>%
### Project to same coordinate system
##st_transform(crs = st_crs(TwoSeas.dat)) %>%
### Trim to area extent
##  st_crop(st_bbox(TwoSeas.dat))

# write_sf(land.barrier, here(dir, "Data", "Shapefiles", "land.barrier.shp"))

plot(land.barrier)

```

# Regroup data 2 Seasons

There is moderate to strong temporal autocorrelation in the model as the modelling mean absolute error is significantly reduced by inclusion of temporal effects. However the spatial effects are not be well captured.

```{r, 2season.structure}

TwoSeas.dat <- full.dat %>%
  mutate(Date = as.Date(dattmPC),
         Season = case_when(
           month(Date) %in% 1:6 ~ "S1",
           month(Date) %in% 7:12 ~ "S2"
           ),
         # Create combined time step variable using year and season
         YearSeas = paste(year(Date), Season, sep = ""),
         Season.nm = 
           case_when(
             grepl("S1", Season) ~ 1,
             grepl("S2", Season) ~ 2
             ),
         # Combine year and numeric season
         YearSeas.nm = (Year + (Season.nm - 1) / 10))
# View(TwoSeas.dat)  

unique(TwoSeas.dat$YearSeas)
unique(TwoSeas.dat$YearSeas.nm)


# Remove 2003 and 2007 data
TwoSeas.dat <- TwoSeas.dat %>%
  filter(!Year %in% c(2003, 2007))

```

# Find Missing Seasons

```{r, missing.seasons}

# Generate complete sequence
# Define the range of years
years <- 2003:2024

# Create the sequence of year-season combinations
year_season_sequence <- data.frame(
  YearSeas.nm = unlist(lapply(years, function(year) {
  # For each year, create two entries: season 1 (0.0) and season 2 (0.1)
  ## year + 0/10 gives 2003.0,while year + 1/10 gives 2003.1
  c(year + 0 / 10, year + 1 / 10)  
}))
)

# Print the resulting sequence
year_season_sequence

missing_seas <- year_season_sequence %>%
  anti_join(TwoSeas.dat, by = "YearSeas.nm") %>%
  select(YearSeas.nm)

missing_seas

```

## Find missing time steps

```{r}

# Define all levels for Year Quarter, combining training data and extra_time (numeric)
all_levels2 <- sort(unique(c(TwoSeas.dat$YearSeas.nm, missing_seas$YearSeas.nm)))

# Define extra time steps to estimate
est.missing.time2 <- unique(missing_seas$YearSeas.nm) %>%
  sort

save(est.missing.time2, file = here(dir, "Data", "ExampleRun",
                                    "est.missing.time2.rda"))

```

# Explore the data

Because we have sparse data with biased sampling, remove 2003 and 2007 where sampling occured over a limited range and where there are problems in estimated transect location.

```{r, simplify.model}

TwoSeas.dat.0s <- TwoSeas.dat %>%
  filter(sciname == "Other")

TwoSeas.sar <- TwoSeas.dat %>%
  filter(sciname != "Other")

ggplot() +
  geom_sf(data = land.barrier, fill = "palegreen") +
  geom_sf(data = TwoSeas.dat.0s, ol = "darkred") +
  geom_sf(data = TwoSeas.sar, col = "black")

st_bbox(TwoSeas.sar)
#       xmin       ymin       xmax       ymax 
#  -248448.9 -1218974.1   946410.3  1136329.6

```

# Create X Y columns

```{r, x.y.columns}

# Extract polygon centers
TwoSeas.dat2 <- TwoSeas.dat %>%
  # Extract the centre of the transect (this is in km)
  mutate(X = st_coordinates(st_centroid(.))[,1]/1000,
         Y = st_coordinates(st_centroid(.))[,2]/1000) %>%
  st_drop_geometry() 

# View(TwoSeas.dat2)
fwrite(TwoSeas.dat2, here(dir, "Data", "TwoSeas.dat2.no.clust"))

```

# Construct the Seasonal Mesh: 

## Creat Barrier Mesh

```{r, construct.barrier.mesh}

# Filter the data frame
TwoSeas.dat2_filtered <- 
  TwoSeas.dat2[TwoSeas.dat2$X >= min(TwoSeas.dat2$X) & 
                 TwoSeas.dat2$X <= max(TwoSeas.dat2$X) & 
                 TwoSeas.dat2$Y >= min(TwoSeas.dat2$Y) & 
                 TwoSeas.dat2$Y <= max(TwoSeas.dat2$Y), ]

# Cutoff values control the minimum distance between knots.
## It is generally better to start with a coarser mesh (larger cutoff)
## However there is a tradeoff on spatial predictability (more knots) and
## over fitting the time to process. If the day is irregularly distributed
## you can also try residual-based knot placement
meshTwoSeas.dat2_filtered <- make_mesh(TwoSeas.dat2_filtered, xy_cols = c("X", "Y"), cutoff = 50) 

# Check number of mesh nodes 
## If greater than >1,000–2,000 nodes, 
## you’re likely in trouble unless you have a lot of RAM.
length(meshTwoSeas.dat2_filtered$mesh$loc[,1])
# [1] 270

plot(meshTwoSeas.dat2_filtered)
points(TwoSeas.dat2_filtered$X, TwoSeas.dat2_filtered$Y, col = "red", pch = 19, 
       cex = 0.2) 

# proj_scaling should match units of (since we are working in m, but density
# is in km, divide by 1000)
barrier2 <- sdmTMBextra::add_barrier_mesh(meshTwoSeas.dat2_filtered, land.barrier, proj_scaling = 1000)

## If greater than >1,000–2,000 nodes, 
## you’re likely in trouble unless you have a lot of RAM.
length(barrier2$mesh$loc[,1])
# [1] 270

# Example plot code from ?add_barrier_mesh
mesh_df_water2 <- barrier2$mesh_sf[barrier2$normal_triangles, ]
mesh_df_land2 <- barrier2$mesh_sf[barrier2$barrier_triangles, ]

Mesh.with.barrier2 <-
ggplot() +
  geom_sf(data = land.barrier) +
  geom_sf(data = mesh_df_water2, size = 1, colour = "blue") +
  geom_sf(data = mesh_df_land2, size = 1, colour = "green")

Mesh.with.barrier2

plot(meshTwoSeas.dat2_filtered)
points(TwoSeas.dat2_filtered$X, TwoSeas.dat2_filtered$Y, col = "red", pch = 19, 
       cex = 0.2) 

```
